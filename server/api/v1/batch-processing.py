"""ç¬¬ä¸‰é˜¶æ®µï¼šæ‰¹é‡å¤„ç† API - Batch Processing API

åŠŸèƒ½ï¼š
- å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- æ‰¹é‡ç…§ç‰‡å¤„ç†
- é¢„è®¾åº”ç”¨
- è¿›åº¦è¿½è¸ª
- WebSocket å®æ—¶æ¨é€

æ€§èƒ½ç›®æ ‡ï¼š
- å¤„ç†é€Ÿåº¦ï¼š< 30ç§’/50å¼ 
- å†…å­˜å ç”¨ï¼š< 500MB
- é˜Ÿåˆ—å¤§å°ï¼š100+ ä»»åŠ¡
- å¹¶å‘å¤„ç†ï¼š4-8 ä¸ªä»»åŠ¡

ä½œè€…ï¼šManus AI
æ—¥æœŸï¼š2025-01-13
\"\"\"\n\nimport asyncio\nimport json\nimport os\nimport uuid\nfrom datetime import datetime, timedelta\nfrom typing import Optional, List, Dict, Any\nfrom enum import Enum\n\nfrom fastapi import FastAPI, WebSocket, UploadFile, File, Form, HTTPException\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nimport aioredis\nfrom aioredis import Redis\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport io\n\n# ============ ç±»å‹å®šä¹‰ ============\n\nclass TaskStatus(str, Enum):\n    \"\"\"ä»»åŠ¡çŠ¶æ€\"\"\"\n    QUEUED = \"queued\"           # å·²æ’é˜Ÿ\n    PROCESSING = \"processing\"   # å¤„ç†ä¸­\n    COMPLETED = \"completed\"     # å·²å®Œæˆ\n    FAILED = \"failed\"           # å¤±è´¥\n    CANCELLED = \"cancelled\"     # å·²å–æ¶ˆ\n\nclass PresetType(str, Enum):\n    \"\"\"é¢„è®¾ç±»å‹\"\"\"\n    BEAUTY = \"beauty\"           # ç¾é¢œé¢„è®¾\n    FILTER = \"filter\"           # æ»¤é•œé¢„è®¾\n    COLOR = \"color\"             # è°ƒè‰²é¢„è®¾\n    INPAINT = \"inpaint\"         # AI æ¶ˆé™¤é¢„è®¾\n\nclass BatchTask(BaseModel):\n    \"\"\"æ‰¹é‡ä»»åŠ¡\"\"\"\n    task_id: str\n    user_id: str\n    image_urls: List[str]\n    preset_type: PresetType\n    preset_params: Dict[str, Any]\n    status: TaskStatus = TaskStatus.QUEUED\n    progress: int = 0\n    total_images: int\n    processed_images: int = 0\n    failed_images: int = 0\n    created_at: datetime\n    updated_at: datetime\n    estimated_time: Optional[int] = None  # é¢„è®¡å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰\n\nclass PresetConfig(BaseModel):\n    \"\"\"é¢„è®¾é…ç½®\"\"\"\n    preset_id: str\n    preset_name: str\n    preset_type: PresetType\n    params: Dict[str, Any]\n    description: Optional[str] = None\n    thumbnail_url: Optional[str] = None\n\n# ============ å¸¸é‡ ============\n\nREDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\nMAX_WORKERS = int(os.getenv(\"BATCH_MAX_WORKERS\", \"4\"))\nMAX_QUEUE_SIZE = int(os.getenv(\"BATCH_MAX_QUEUE_SIZE\", \"100\"))\nTASK_TIMEOUT = int(os.getenv(\"BATCH_TASK_TIMEOUT\", \"300\"))  # 5 åˆ†é’Ÿ\nTASK_RETRY_COUNT = int(os.getenv(\"BATCH_TASK_RETRY_COUNT\", \"3\"))\n\n# ============ FastAPI åº”ç”¨ ============\n\napp = FastAPI(title=\"Batch Processing API\", version=\"1.0.0\")\n\n# ============ å…¨å±€çŠ¶æ€ ============\n\nredis: Optional[Redis] = None\ntask_queue: asyncio.Queue = asyncio.Queue(maxsize=MAX_QUEUE_SIZE)\nactive_tasks: Dict[str, BatchTask] = {}\nworkers: List[asyncio.Task] = []\n\n# ============ åˆå§‹åŒ–å’Œå…³é—­ ============\n\n@app.on_event(\"startup\")\nasync def startup():\n    \"\"\"å¯åŠ¨æ—¶åˆå§‹åŒ– Redis å’Œ Worker\"\"\"\n    global redis\n    \n    try:\n        redis = await aioredis.create_redis_pool(REDIS_URL)\n        print(f\"âœ… Redis è¿æ¥æˆåŠŸ: {REDIS_URL}\")\n    except Exception as e:\n        print(f\"âŒ Redis è¿æ¥å¤±è´¥: {e}\")\n        redis = None\n    \n    # å¯åŠ¨ Worker\n    for i in range(MAX_WORKERS):\n        worker = asyncio.create_task(batch_worker(i))\n        workers.append(worker)\n        print(f\"âœ… Worker {i} å·²å¯åŠ¨\")\n\n@app.on_event(\"shutdown\")\nasync def shutdown():\n    \"\"\"å…³é—­æ—¶æ¸…ç†èµ„æº\"\"\"\n    global redis\n    \n    # å–æ¶ˆæ‰€æœ‰ Worker\n    for worker in workers:\n        worker.cancel()\n    \n    # å…³é—­ Redis\n    if redis:\n        redis.close()\n        await redis.wait_closed()\n        print(\"âœ… Redis è¿æ¥å·²å…³é—­\")\n\n# ============ Worker å¤„ç† ============\n\nasync def batch_worker(worker_id: int):\n    \"\"\"æ‰¹é‡å¤„ç† Worker\"\"\"\n    print(f\"ğŸš€ Worker {worker_id} å¼€å§‹è¿è¡Œ\")\n    \n    while True:\n        try:\n            # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡\n            task = await asyncio.wait_for(task_queue.get(), timeout=30)\n            \n            if task is None:  # å“¨å…µå€¼ï¼Œè¡¨ç¤ºå…³é—­\n                break\n            \n            print(f\"ğŸ‘· Worker {worker_id} å¤„ç†ä»»åŠ¡: {task.task_id}\")\n            \n            # å¤„ç†ä»»åŠ¡\n            await process_batch_task(task, worker_id)\n            \n        except asyncio.TimeoutError:\n            # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…\n            continue\n        except asyncio.CancelledError:\n            print(f\"âš ï¸ Worker {worker_id} å·²å–æ¶ˆ\")\n            break\n        except Exception as e:\n            print(f\"âŒ Worker {worker_id} é”™è¯¯: {e}\")\n            continue\n\nasync def process_batch_task(task: BatchTask, worker_id: int):\n    \"\"\"å¤„ç†æ‰¹é‡ä»»åŠ¡\"\"\"\n    try:\n        # æ›´æ–°ä»»åŠ¡çŠ¶æ€\n        task.status = TaskStatus.PROCESSING\n        task.updated_at = datetime.now()\n        active_tasks[task.task_id] = task\n        \n        # ä¿å­˜åˆ° Redis\n        if redis:\n            await redis.setex(\n                f\"batch_task:{task.task_id}\",\n                TASK_TIMEOUT,\n                json.dumps(task.dict(), default=str)\n            )\n        \n        # å¤„ç†æ¯å¼ å›¾ç‰‡\n        total = len(task.image_urls)\n        for idx, image_url in enumerate(task.image_urls):\n            try:\n                # ä¸‹è½½å’Œå¤„ç†å›¾ç‰‡\n                result = await process_single_image(\n                    image_url,\n                    task.preset_type,\n                    task.preset_params\n                )\n                \n                # æ›´æ–°è¿›åº¦\n                task.processed_images += 1\n                task.progress = int((task.processed_images / total) * 100)\n                task.updated_at = datetime.now()\n                \n                # è®¡ç®—é¢„è®¡å‰©ä½™æ—¶é—´\n                elapsed = (task.updated_at - task.created_at).total_seconds()\n                avg_time_per_image = elapsed / (idx + 1)\n                remaining_images = total - task.processed_images\n                task.estimated_time = int(avg_time_per_image * remaining_images)\n                \n                # ä¿å­˜è¿›åº¦åˆ° Redis\n                if redis:\n                    await redis.setex(\n                        f\"batch_task:{task.task_id}\",\n                        TASK_TIMEOUT,\n                        json.dumps(task.dict(), default=str)\n                    )\n                \n                print(f\"âœ… Worker {worker_id} å¤„ç†å®Œæˆ: {image_url} ({task.progress}%)\")\n                \n            except Exception as e:\n                print(f\"âŒ Worker {worker_id} å¤„ç†å¤±è´¥: {image_url} - {e}\")\n                task.failed_images += 1\n        \n        # ä»»åŠ¡å®Œæˆ\n        task.status = TaskStatus.COMPLETED\n        task.updated_at = datetime.now()\n        \n        # ä¿å­˜æœ€ç»ˆç»“æœåˆ° Redis\n        if redis:\n            await redis.setex(\n                f\"batch_task:{task.task_id}\",\n                TASK_TIMEOUT,\n                json.dumps(task.dict(), default=str)\n            )\n        \n        print(f\"âœ… Worker {worker_id} ä»»åŠ¡å®Œæˆ: {task.task_id}\")\n        \n    except Exception as e:\n        print(f\"âŒ Worker {worker_id} ä»»åŠ¡å¤±è´¥: {e}\")\n        task.status = TaskStatus.FAILED\n        task.updated_at = datetime.now()\n        \n        if redis:\n            await redis.setex(\n                f\"batch_task:{task.task_id}\",\n                TASK_TIMEOUT,\n                json.dumps(task.dict(), default=str)\n            )\n\nasync def process_single_image(\n    image_url: str,\n    preset_type: PresetType,\n    preset_params: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"å¤„ç†å•å¼ å›¾ç‰‡\"\"\"\n    # TODO: å®ç°å…·ä½“çš„å›¾ç‰‡å¤„ç†é€»è¾‘\n    # è¿™é‡Œæ˜¯å ä½ç¬¦å®ç°\n    \n    await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n    \n    return {\n        \"status\": \"success\",\n        \"image_url\": image_url,\n        \"processed_url\": f\"{image_url}_processed\",\n    }\n\n# ============ API ç«¯ç‚¹ ============\n\n@app.post(\"/api/v1/batch/submit\")\nasync def submit_batch_task(\n    user_id: str = Form(...),\n    image_urls: str = Form(...),  # JSON å­—ç¬¦ä¸²\n    preset_type: str = Form(...),\n    preset_params: str = Form(...),  # JSON å­—ç¬¦ä¸²\n) -> JSONResponse:\n    \"\"\"æäº¤æ‰¹é‡å¤„ç†ä»»åŠ¡\"\"\"\n    try:\n        # è§£æå‚æ•°\n        image_urls_list = json.loads(image_urls)\n        preset_params_dict = json.loads(preset_params)\n        \n        # éªŒè¯å‚æ•°\n        if not image_urls_list or len(image_urls_list) == 0:\n            raise HTTPException(status_code=400, detail=\"å›¾ç‰‡åˆ—è¡¨ä¸èƒ½ä¸ºç©º\")\n        \n        if len(image_urls_list) > 100:\n            raise HTTPException(status_code=400, detail=\"æœ€å¤šæ”¯æŒ 100 å¼ å›¾ç‰‡\")\n        \n        # åˆ›å»ºä»»åŠ¡\n        task_id = str(uuid.uuid4())\n        task = BatchTask(\n            task_id=task_id,\n            user_id=user_id,\n            image_urls=image_urls_list,\n            preset_type=PresetType(preset_type),\n            preset_params=preset_params_dict,\n            total_images=len(image_urls_list),\n            created_at=datetime.now(),\n            updated_at=datetime.now(),\n        )\n        \n        # æ·»åŠ åˆ°é˜Ÿåˆ—\n        try:\n            task_queue.put_nowait(task)\n        except asyncio.QueueFull:\n            raise HTTPException(status_code=503, detail=\"ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ï¼Œè¯·ç¨åé‡è¯•\")\n        \n        # ä¿å­˜åˆ° Redis\n        if redis:\n            await redis.setex(\n                f\"batch_task:{task_id}\",\n                TASK_TIMEOUT,\n                json.dumps(task.dict(), default=str)\n            )\n        \n        active_tasks[task_id] = task\n        \n        return JSONResponse({\n            \"status\": \"success\",\n            \"task_id\": task_id,\n            \"message\": \"ä»»åŠ¡å·²æäº¤\",\n        })\n        \n    except json.JSONDecodeError as e:\n        raise HTTPException(status_code=400, detail=f\"JSON è§£æé”™è¯¯: {e}\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/api/v1/batch/{task_id}\")\nasync def get_batch_task_status(task_id: str) -> JSONResponse:\n    \"\"\"è·å–æ‰¹é‡ä»»åŠ¡çŠ¶æ€\"\"\"\n    try:\n        # å…ˆä»å†…å­˜è·å–\n        if task_id in active_tasks:\n            task = active_tasks[task_id]\n            return JSONResponse({\n                \"status\": \"success\",\n                \"task\": task.dict(default=str),\n            })\n        \n        # å†ä» Redis è·å–\n        if redis:\n            task_data = await redis.get(f\"batch_task:{task_id}\")\n            if task_data:\n                task_dict = json.loads(task_data)\n                return JSONResponse({\n                    \"status\": \"success\",\n                    \"task\": task_dict,\n                })\n        \n        raise HTTPException(status_code=404, detail=\"ä»»åŠ¡ä¸å­˜åœ¨\")\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/api/v1/batch/{task_id}/cancel\")\nasync def cancel_batch_task(task_id: str) -> JSONResponse:\n    \"\"\"å–æ¶ˆæ‰¹é‡ä»»åŠ¡\"\"\"\n    try:\n        if task_id in active_tasks:\n            task = active_tasks[task_id]\n            task.status = TaskStatus.CANCELLED\n            task.updated_at = datetime.now()\n            \n            if redis:\n                await redis.setex(\n                    f\"batch_task:{task_id}\",\n                    TASK_TIMEOUT,\n                    json.dumps(task.dict(), default=str)\n                )\n            \n            return JSONResponse({\n                \"status\": \"success\",\n                \"message\": \"ä»»åŠ¡å·²å–æ¶ˆ\",\n            })\n        \n        raise HTTPException(status_code=404, detail=\"ä»»åŠ¡ä¸å­˜åœ¨\")\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/api/v1/batch/stats\")\nasync def get_batch_stats() -> JSONResponse:\n    \"\"\"è·å–æ‰¹é‡å¤„ç†ç»Ÿè®¡ä¿¡æ¯\"\"\"\n    try:\n        total_tasks = len(active_tasks)\n        processing_tasks = sum(1 for t in active_tasks.values() if t.status == TaskStatus.PROCESSING)\n        completed_tasks = sum(1 for t in active_tasks.values() if t.status == TaskStatus.COMPLETED)\n        failed_tasks = sum(1 for t in active_tasks.values() if t.status == TaskStatus.FAILED)\n        \n        return JSONResponse({\n            \"status\": \"success\",\n            \"stats\": {\n                \"total_tasks\": total_tasks,\n                \"processing_tasks\": processing_tasks,\n                \"completed_tasks\": completed_tasks,\n                \"failed_tasks\": failed_tasks,\n                \"queue_size\": task_queue.qsize(),\n                \"max_queue_size\": MAX_QUEUE_SIZE,\n                \"workers\": MAX_WORKERS,\n            },\n        })\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/api/v1/health\")\nasync def health_check() -> JSONResponse:\n    \"\"\"å¥åº·æ£€æŸ¥\"\"\"\n    redis_status = \"connected\" if redis else \"disconnected\"\n    \n    return JSONResponse({\n        \"status\": \"healthy\",\n        \"redis\": redis_status,\n        \"workers\": len(workers),\n        \"timestamp\": datetime.now().isoformat(),\n    })\n\n# ============ WebSocket ç«¯ç‚¹ ============\n\n@app.websocket(\"/ws/batch/{task_id}\")\nasync def websocket_batch_progress(websocket: WebSocket, task_id: str):\n    \"\"\"WebSocket å®æ—¶æ¨é€æ‰¹é‡ä»»åŠ¡è¿›åº¦\"\"\"\n    await websocket.accept()\n    \n    try:\n        while True:\n            # è·å–ä»»åŠ¡çŠ¶æ€\n            if task_id in active_tasks:\n                task = active_tasks[task_id]\n            elif redis:\n                task_data = await redis.get(f\"batch_task:{task_id}\")\n                if task_data:\n                    task_dict = json.loads(task_data)\n                    task = BatchTask(**task_dict)\n                else:\n                    await websocket.send_json({\n                        \"status\": \"error\",\n                        \"message\": \"ä»»åŠ¡ä¸å­˜åœ¨\",\n                    })\n                    break\n            else:\n                await websocket.send_json({\n                    \"status\": \"error\",\n                    \"message\": \"ä»»åŠ¡ä¸å­˜åœ¨\",\n                })\n                break\n            \n            # æ¨é€è¿›åº¦\n            await websocket.send_json({\n                \"status\": \"success\",\n                \"task_id\": task_id,\n                \"progress\": task.progress,\n                \"processed_images\": task.processed_images,\n                \"total_images\": task.total_images,\n                \"failed_images\": task.failed_images,\n                \"estimated_time\": task.estimated_time,\n                \"task_status\": task.status.value,\n            })\n            \n            # å¦‚æœä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼Œæ–­å¼€è¿æ¥\n            if task.status in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED]:\n                break\n            \n            # æ¯ 1 ç§’æ›´æ–°ä¸€æ¬¡\n            await asyncio.sleep(1)\n        \n    except Exception as e:\n        print(f\"âŒ WebSocket é”™è¯¯: {e}\")\n    finally:\n        await websocket.close()\n\n# ============ ä¸»ç¨‹åº ============\n\nif __name__ == \"__main__\":\n    import uvicorn\n    \n    port = int(os.getenv(\"BATCH_API_PORT\", \"8001\"))\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=port,\n        log_level=\"info\",\n    )\n
