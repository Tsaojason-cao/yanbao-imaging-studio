# yanbao AI - åŠ å¼ºç‰ˆæ™ºèƒ½åŒ–æ‰§è¡Œæ–¹æ¡ˆ

## ğŸ¯ æ ¸å¿ƒåŠ å¼ºç‚¹

æœ¬æ–¹æ¡ˆåœ¨åŸæœ‰åŸºç¡€ä¸Šå¢åŠ äº† **4 å¤§å…³é”®åŠ å¼º**ï¼š

1. **åŒè½¨åˆ¶æ¥å£**ï¼ˆé˜²å‘†æœºåˆ¶ï¼‰ - ç¡®ä¿æ™ºèƒ½åŒ–å‡çº§æœŸé—´ç³»ç»Ÿç¨³å®š
2. **æƒ…æ„Ÿè®°å¿†ç»´åº¦** - è®© AI ç†è§£ç”¨æˆ·çš„æƒ…ç»ªå’Œåå¥½
3. **å¤§å¸ˆåæ€æœºåˆ¶** - è®© AI çŸ¥é“è‡ªå·±"çŸ¥ä¸çŸ¥é“"
4. **é¢„æµ‹æ€§äº¤äº’** - ä¸»åŠ¨æ¨é€ï¼Œå‡å°‘ç”¨æˆ·æ“ä½œè·¯å¾„

---

## ğŸ“… ä¿®æ­£åçš„æ ¸å¿ƒæ‰§è¡ŒæŒ‡æ ‡è¡¨

| é˜¶æ®µ | ä»»åŠ¡ | å¿…é¡»åŠ å¼ºçš„æ™ºèƒ½åŒ–æŒ‡æ ‡ | éªŒæ”¶æ ‡å‡† |
|------|------|---------------------|----------|
| **D1: åŸºçŸ³** | æ¶æ„æ ¡å¯¹ | **å½±å­é€»è¾‘éš”ç¦»**ï¼šç¡®ä¿é‡æ„ä¸å½±å“ç°æœ‰ v1.0 åŠŸèƒ½ | âœ… åŒè½¨åˆ¶æ¥å£éƒ¨ç½²å®Œæˆ<br>âœ… é™çº§ä¿æŠ¤æµ‹è¯•é€šè¿‡ |
| **D2: å¤§è„‘** | å¤§å¸ˆé‡å¡‘ | **åŒé‡æ¨ç†**ï¼šCoT å¿…é¡»åŒ…å«"æ„å›¾è¯†åˆ«"ä¸"ä¸“ä¸šåº“åŒ¹é…"ä¸¤ä¸ªæ­¥éª¤ | âœ… åæ€æœºåˆ¶å®ç°<br>âœ… è‡ªæˆ‘æ ¡å¯¹åŠŸèƒ½æµ‹è¯•é€šè¿‡ |
| **D3: ç¥ç»** | è®°å¿†æ¥å…¥ | **å¤šç»´å‘é‡**ï¼šåŒ…å«æ—¶é—´ã€åœ°ç‚¹ã€æƒ…æ„Ÿã€å®¡ç¾åå¥½å››ä½ä¸€ä½“çš„æ£€ç´¢ | âœ… æƒ…æ„Ÿæ ‡ç­¾ç³»ç»Ÿéƒ¨ç½²<br>âœ… æ“ä½œé¢‘ç‡æƒé‡è®¡ç®— |
| **D4: æ„ŸçŸ¥** | åª’ä½“é›†æˆ | **å‚æ•°è‡ªé€‚åº”**ï¼šå®ç°ä»è‡ªç„¶è¯­è¨€åˆ°ä¸“ä¸šæ‘„å½±å‚æ•°çš„ç²¾å‡†æ˜ å°„ | âœ… è¯­ä¹‰ä¿®å›¾åŠŸèƒ½<br>âœ… "æ˜¨å¤©çš„æ„Ÿè§‰"èƒ½ç²¾å‡†è¿˜åŸ |
| **D5: æ„å›¾** | åœ°å›¾é›†æˆ | **ä¸»åŠ¨å¼æ¨é€**ï¼šåŸºäº"è®°å¿†é¿é›·é’ˆ"é€»è¾‘ï¼Œä¸»åŠ¨å±è”½ç”¨æˆ·è®¨åŒçš„é£æ ¼åœ°ç‚¹ | âœ… åŠ¨æ€é¿é›·åŠŸèƒ½<br>âœ… ä¸»åŠ¨æ¨èå‘½ä¸­ç‡ > 60% |
| **D6: åŒ…è£…** | UI/UX ä¼˜åŒ– | **æ±‰åŒ–å®¡è®¡**ï¼šç¡®ä¿é™¤äº† yanbao AIï¼Œå…¨ç³»ç»Ÿæ— äºŒä¹‰æ€§ä¸­æ–‡è¡¨è¿° | âœ… é¢„æµ‹æ€§äº¤äº’ UI<br>âœ… å‰ç½®è§¦å‘åŠŸèƒ½ |
| **D7: å‘å¸ƒ** | æµ‹è¯•ä¸Šçº¿ | **æ¯«ç§’çº§åé¦ˆ**ï¼šè®°å¿†æ£€ç´¢ + æ¨ç†æ€»è€—æ—¶å¿…é¡» < 200ms | âœ… å‹åŠ›æµ‹è¯•é€šè¿‡<br>âœ… å»¶è¿Ÿ < 200ms |

---

## ğŸ›¡ï¸ åŠ å¼ºç‚¹ 1: åŒè½¨åˆ¶æ¥å£ï¼ˆé˜²å‘†æœºåˆ¶ï¼‰

### é—®é¢˜
åœ¨æ™ºèƒ½åŒ–å‡çº§æœŸé—´ï¼Œå¦‚æœè®°å¿†å¼•æ“æˆ– AI æ¨ç†å¤±è´¥ï¼ŒApp ä¸èƒ½å‡ºç°é€»è¾‘çœŸç©ºã€‚

### è§£å†³æ–¹æ¡ˆ
é‡‡ç”¨**åŒè½¨åˆ¶æ¥å£**ï¼Œå®ç°æ™ºèƒ½æ¨¡å¼å’ŒåŸºç¡€æ¨¡å¼çš„æ— ç¼åˆ‡æ¢ã€‚

### æ¶æ„è®¾è®¡

```typescript
// src/services/DualModeService.ts

enum ServiceMode {
  INTELLIGENT = 'intelligent',  // æ™ºèƒ½æ¨¡å¼ï¼ˆAI + è®°å¿†ï¼‰
  FALLBACK = 'fallback'          // é™çº§æ¨¡å¼ï¼ˆåŸºç¡€é€»è¾‘ï¼‰
}

interface ServiceHealth {
  memoryEngine: boolean;
  aiReasoning: boolean;
  vectorSearch: boolean;
  lastCheck: number;
}

class DualModeService {
  private static instance: DualModeService;
  private currentMode: ServiceMode = ServiceMode.INTELLIGENT;
  private health: ServiceHealth = {
    memoryEngine: false,
    aiReasoning: false,
    vectorSearch: false,
    lastCheck: 0
  };
  
  // å¥åº·æ£€æŸ¥é—´éš”ï¼ˆæ¯«ç§’ï¼‰
  private readonly HEALTH_CHECK_INTERVAL = 5000;
  // è¶…æ—¶é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
  private readonly TIMEOUT_THRESHOLD = 200;
  
  static getInstance(): DualModeService {
    if (!DualModeService.instance) {
      DualModeService.instance = new DualModeService();
      DualModeService.instance.startHealthCheck();
    }
    return DualModeService.instance;
  }
  
  /**
   * å¯åŠ¨å¥åº·æ£€æŸ¥
   */
  private startHealthCheck() {
    setInterval(async () => {
      await this.checkHealth();
    }, this.HEALTH_CHECK_INTERVAL);
  }
  
  /**
   * æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€
   */
  private async checkHealth(): Promise<void> {
    const startTime = Date.now();
    
    try {
      // æ£€æŸ¥è®°å¿†å¼•æ“
      this.health.memoryEngine = await this.checkMemoryEngine();
      
      // æ£€æŸ¥ AI æ¨ç†
      this.health.aiReasoning = await this.checkAIReasoning();
      
      // æ£€æŸ¥å‘é‡æ£€ç´¢
      this.health.vectorSearch = await this.checkVectorSearch();
      
      this.health.lastCheck = Date.now();
      
      // æ ¹æ®å¥åº·çŠ¶æ€å†³å®šæ¨¡å¼
      const allHealthy = this.health.memoryEngine && 
                        this.health.aiReasoning && 
                        this.health.vectorSearch;
      
      this.currentMode = allHealthy ? 
        ServiceMode.INTELLIGENT : 
        ServiceMode.FALLBACK;
      
      const checkDuration = Date.now() - startTime;
      console.log(`ğŸ” Health check completed in ${checkDuration}ms, mode: ${this.currentMode}`);
      
    } catch (error) {
      console.error('âŒ Health check failed:', error);
      this.currentMode = ServiceMode.FALLBACK;
    }
  }
  
  /**
   * æ£€æŸ¥è®°å¿†å¼•æ“
   */
  private async checkMemoryEngine(): Promise<boolean> {
    try {
      const startTime = Date.now();
      // ç®€å•çš„ ping æµ‹è¯•
      await fetch('/api/memory/health', { 
        method: 'GET',
        signal: AbortSignal.timeout(this.TIMEOUT_THRESHOLD)
      });
      const duration = Date.now() - startTime;
      return duration < this.TIMEOUT_THRESHOLD;
    } catch {
      return false;
    }
  }
  
  /**
   * æ£€æŸ¥ AI æ¨ç†
   */
  private async checkAIReasoning(): Promise<boolean> {
    try {
      const startTime = Date.now();
      await fetch('/api/master/health', { 
        method: 'GET',
        signal: AbortSignal.timeout(this.TIMEOUT_THRESHOLD)
      });
      const duration = Date.now() - startTime;
      return duration < this.TIMEOUT_THRESHOLD;
    } catch {
      return false;
    }
  }
  
  /**
   * æ£€æŸ¥å‘é‡æ£€ç´¢
   */
  private async checkVectorSearch(): Promise<boolean> {
    try {
      const startTime = Date.now();
      await fetch('/api/vector/health', { 
        method: 'GET',
        signal: AbortSignal.timeout(this.TIMEOUT_THRESHOLD)
      });
      const duration = Date.now() - startTime;
      return duration < this.TIMEOUT_THRESHOLD;
    } catch {
      return false;
    }
  }
  
  /**
   * è·å–å½“å‰æ¨¡å¼
   */
  getCurrentMode(): ServiceMode {
    return this.currentMode;
  }
  
  /**
   * è·å–å¥åº·çŠ¶æ€
   */
  getHealth(): ServiceHealth {
    return { ...this.health };
  }
  
  /**
   * æ™ºèƒ½æ‰§è¡Œï¼ˆå¸¦é™çº§ä¿æŠ¤ï¼‰
   */
  async executeWithFallback<T>(
    intelligentFn: () => Promise<T>,
    fallbackFn: () => Promise<T>
  ): Promise<T> {
    if (this.currentMode === ServiceMode.INTELLIGENT) {
      try {
        const result = await Promise.race([
          intelligentFn(),
          new Promise<never>((_, reject) => 
            setTimeout(() => reject(new Error('Timeout')), this.TIMEOUT_THRESHOLD)
          )
        ]);
        return result;
      } catch (error) {
        console.warn('âš ï¸ Intelligent mode failed, falling back to basic mode');
        return await fallbackFn();
      }
    } else {
      console.log('â„¹ï¸ Using fallback mode');
      return await fallbackFn();
    }
  }
}

export default DualModeService;
export { ServiceMode, ServiceHealth };
```

### ä½¿ç”¨ç¤ºä¾‹

```typescript
// åœ¨ CameraScreen.tsx ä¸­ä½¿ç”¨åŒè½¨åˆ¶æ¥å£

import DualModeService from './services/DualModeService';

const dualMode = DualModeService.getInstance();

const takePhoto = async () => {
  // æ™ºèƒ½æ¨¡å¼ï¼šä½¿ç”¨è®°å¿†å’Œ AI
  const intelligentFn = async () => {
    const memories = await memoryService.retrieve('ç›¸æœºè®¾ç½®åå¥½');
    const advice = await masterService.getAdvice('photography', 'æ‹ç…§å»ºè®®');
    // åº”ç”¨æ™ºèƒ½æ¨è...
    return { mode: 'intelligent', memories, advice };
  };
  
  // é™çº§æ¨¡å¼ï¼šä½¿ç”¨åŸºç¡€é€»è¾‘
  const fallbackFn = async () => {
    // ä½¿ç”¨é»˜è®¤è®¾ç½®
    const defaultSettings = {
      beauty: 50,
      whitening: 30
    };
    return { mode: 'fallback', settings: defaultSettings };
  };
  
  const result = await dualMode.executeWithFallback(intelligentFn, fallbackFn);
  
  if (result.mode === 'fallback') {
    // æ˜¾ç¤ºæç¤º
    Alert.alert('æç¤º', 'AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼');
  }
};
```

---

## ğŸ’– åŠ å¼ºç‚¹ 2: æƒ…æ„Ÿè®°å¿†ç»´åº¦

### é—®é¢˜
å½“å‰çš„è®°å¿†ç³»ç»Ÿåªè®°å½•"ç”¨æˆ·å»è¿‡å¤–æ»©"ï¼Œç¼ºå°‘æƒ…æ„Ÿå’Œåå¥½ç»´åº¦ã€‚

### è§£å†³æ–¹æ¡ˆ
åœ¨å‘é‡æ•°æ®åº“ä¸­å¢åŠ **æƒ…æ„Ÿæ ‡ç­¾**å’Œ**æ“ä½œé¢‘ç‡æƒé‡**ã€‚

### æ•°æ®ç»“æ„è®¾è®¡

```typescript
// src/types/Memory.ts

interface EmotionalMemory {
  id: string;
  userId: string;
  type: 'photo' | 'recipe' | 'footprint' | 'preference';
  content: string;
  
  // åŸºç¡€å…ƒæ•°æ®
  metadata: {
    timestamp: number;
    location?: string;
    device?: string;
  };
  
  // æƒ…æ„Ÿç»´åº¦ â­ æ–°å¢
  emotional: {
    mood: 'happy' | 'calm' | 'excited' | 'melancholy' | 'neutral';
    satisfaction: number;  // 1-5 æ˜Ÿè¯„åˆ†
    tags: string[];        // å¦‚ï¼š['æµªæ¼«', 'å¤å¤', 'æ¸…æ–°']
  };
  
  // æ“ä½œé¢‘ç‡æƒé‡ â­ æ–°å¢
  frequency: {
    useCount: number;      // ä½¿ç”¨æ¬¡æ•°
    lastUsed: number;      // æœ€åä½¿ç”¨æ—¶é—´
    avgDuration: number;   // å¹³å‡ä½¿ç”¨æ—¶é•¿ï¼ˆç§’ï¼‰
    weight: number;        // ç»¼åˆæƒé‡ï¼ˆ0-1ï¼‰
  };
  
  // å®¡ç¾åå¥½ â­ æ–°å¢
  aesthetic: {
    colorTone: 'warm' | 'cold' | 'neutral';
    brightness: 'bright' | 'dark' | 'balanced';
    style: string[];       // å¦‚ï¼š['ç®€çº¦', 'å¤å¤', 'èµ›åšæœ‹å…‹']
  };
  
  // å‘é‡ embedding
  embedding: number[];
}
```

### æƒ…æ„Ÿåˆ†æå®ç°

```python
# backend/emotional_analyzer.py

from typing import Dict, List
from openai import OpenAI
import json

class EmotionalAnalyzer:
    """
    æƒ…æ„Ÿåˆ†æå™¨ - ä»ç”¨æˆ·è¡Œä¸ºä¸­æå–æƒ…æ„Ÿç»´åº¦
    """
    
    def __init__(self):
        self.client = OpenAI()
    
    def analyze_photo_emotion(
        self,
        photo_metadata: Dict,
        user_actions: List[Dict]
    ) -> Dict:
        """
        åˆ†æç…§ç‰‡çš„æƒ…æ„Ÿç»´åº¦
        
        Args:
            photo_metadata: ç…§ç‰‡å…ƒæ•°æ®ï¼ˆåœ°ç‚¹ã€æ—¶é—´ã€è®¾å¤‡ç­‰ï¼‰
            user_actions: ç”¨æˆ·å¯¹è¿™å¼ ç…§ç‰‡çš„æ“ä½œï¼ˆç¼–è¾‘ã€åˆ†äº«ã€æ”¶è—ç­‰ï¼‰
        
        Returns:
            {
                "mood": "happy",
                "satisfaction": 4.5,
                "tags": ["æµªæ¼«", "æ¸©é¦¨"],
                "colorTone": "warm",
                "style": ["å¤å¤"]
            }
        """
        
        # 1. åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼
        behavior_score = self._analyze_behavior(user_actions)
        
        # 2. ä½¿ç”¨ AI åˆ†ææƒ…æ„Ÿ
        emotion_analysis = self._ai_analyze_emotion(
            photo_metadata,
            user_actions,
            behavior_score
        )
        
        return emotion_analysis
    
    def _analyze_behavior(self, user_actions: List[Dict]) -> float:
        """
        åˆ†æç”¨æˆ·è¡Œä¸ºï¼Œè®¡ç®—æ»¡æ„åº¦åˆ†æ•°
        """
        score = 3.0  # åŸºç¡€åˆ†
        
        for action in user_actions:
            if action['type'] == 'favorite':
                score += 1.0
            elif action['type'] == 'share':
                score += 0.8
            elif action['type'] == 'edit':
                score += 0.3
            elif action['type'] == 'delete':
                score -= 2.0
        
        return max(1.0, min(5.0, score))
    
    def _ai_analyze_emotion(
        self,
        photo_metadata: Dict,
        user_actions: List[Dict],
        behavior_score: float
    ) -> Dict:
        """
        ä½¿ç”¨ AI åˆ†ææƒ…æ„Ÿç»´åº¦
        """
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""åˆ†æè¿™å¼ ç…§ç‰‡çš„æƒ…æ„Ÿç»´åº¦ï¼š

ç…§ç‰‡ä¿¡æ¯ï¼š
- åœ°ç‚¹ï¼š{photo_metadata.get('location', 'æœªçŸ¥')}
- æ—¶é—´ï¼š{photo_metadata.get('time', 'æœªçŸ¥')}
- è®¾å¤‡ï¼š{photo_metadata.get('device', 'æœªçŸ¥')}

ç”¨æˆ·è¡Œä¸ºï¼š
{json.dumps(user_actions, ensure_ascii=False)}

è¡Œä¸ºæ»¡æ„åº¦åˆ†æ•°ï¼š{behavior_score}/5.0

è¯·åˆ†æå¹¶è¿”å› JSON æ ¼å¼ï¼š
{{
  "mood": "happy/calm/excited/melancholy/neutral",
  "satisfaction": 1-5,
  "tags": ["æƒ…æ„Ÿæ ‡ç­¾1", "æƒ…æ„Ÿæ ‡ç­¾2"],
  "colorTone": "warm/cold/neutral",
  "brightness": "bright/dark/balanced",
  "style": ["é£æ ¼æ ‡ç­¾1", "é£æ ¼æ ‡ç­¾2"]
}}"""
            }],
            response_format={"type": "json_object"}
        )
        
        return json.loads(response.choices[0].message.content)
    
    def calculate_frequency_weight(
        self,
        use_count: int,
        last_used: int,
        avg_duration: float
    ) -> float:
        """
        è®¡ç®—æ“ä½œé¢‘ç‡æƒé‡
        
        æƒé‡å…¬å¼ï¼š
        weight = (use_count * 0.4) + (recency * 0.3) + (duration * 0.3)
        """
        import time
        
        # ä½¿ç”¨æ¬¡æ•°æƒé‡ï¼ˆå½’ä¸€åŒ–åˆ° 0-1ï¼‰
        use_weight = min(use_count / 10.0, 1.0)
        
        # æ—¶é—´æ–°é²œåº¦æƒé‡
        days_since_use = (time.time() - last_used) / 86400
        recency_weight = max(0, 1.0 - (days_since_use / 30.0))
        
        # ä½¿ç”¨æ—¶é•¿æƒé‡ï¼ˆå½’ä¸€åŒ–åˆ° 0-1ï¼‰
        duration_weight = min(avg_duration / 300.0, 1.0)
        
        # ç»¼åˆæƒé‡
        weight = (use_weight * 0.4) + (recency_weight * 0.3) + (duration_weight * 0.3)
        
        return round(weight, 3)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    analyzer = EmotionalAnalyzer()
    
    result = analyzer.analyze_photo_emotion(
        photo_metadata={
            "location": "å¤–æ»©",
            "time": "å‚æ™š",
            "device": "iPhone 15 Pro"
        },
        user_actions=[
            {"type": "favorite", "timestamp": 1705449600},
            {"type": "share", "timestamp": 1705450000},
            {"type": "edit", "timestamp": 1705450200}
        ]
    )
    
    print("=== æƒ…æ„Ÿåˆ†æç»“æœ ===")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    weight = analyzer.calculate_frequency_weight(
        use_count=5,
        last_used=int(time.time()) - 86400,  # 1å¤©å‰
        avg_duration=180  # 3åˆ†é’Ÿ
    )
    
    print(f"\næ“ä½œé¢‘ç‡æƒé‡ï¼š{weight}")
```

### æƒ…æ„Ÿè®°å¿†æ£€ç´¢

```python
# backend/emotional_memory_service.py

class EmotionalMemoryService:
    """
    æƒ…æ„Ÿè®°å¿†æœåŠ¡ - åŸºäºæƒ…æ„Ÿç»´åº¦çš„æ™ºèƒ½æ£€ç´¢
    """
    
    def retrieve_by_emotion(
        self,
        user_id: str,
        query: str,
        emotional_context: Dict = None
    ) -> List[Dict]:
        """
        åŸºäºæƒ…æ„Ÿç»´åº¦æ£€ç´¢è®°å¿†
        
        Args:
            user_id: ç”¨æˆ· ID
            query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¦‚"æ˜¨å¤©çš„æ„Ÿè§‰"ï¼‰
            emotional_context: å½“å‰æƒ…æ„Ÿä¸Šä¸‹æ–‡
        
        Returns:
            æŒ‰æƒé‡æ’åºçš„è®°å¿†åˆ—è¡¨
        """
        
        # 1. åˆ†ææŸ¥è¯¢æ„å›¾
        intent = self._analyze_query_intent(query)
        
        # 2. æ„å»ºæƒ…æ„Ÿè¿‡æ»¤å™¨
        emotional_filter = self._build_emotional_filter(
            intent,
            emotional_context
        )
        
        # 3. å‘é‡æ£€ç´¢
        results = self.vector_db.query(
            user_id=user_id,
            query_text=query,
            filter=emotional_filter,
            top_k=10
        )
        
        # 4. æŒ‰é¢‘ç‡æƒé‡é‡æ–°æ’åº
        weighted_results = sorted(
            results,
            key=lambda x: x['frequency']['weight'],
            reverse=True
        )
        
        return weighted_results[:5]
    
    def _analyze_query_intent(self, query: str) -> Dict:
        """
        åˆ†ææŸ¥è¯¢æ„å›¾
        """
        # æƒ…æ„Ÿå…³é”®è¯æ˜ å°„
        emotional_keywords = {
            "æ˜¨å¤©çš„æ„Ÿè§‰": {"mood": "nostalgic", "time_range": "recent"},
            "å¼€å¿ƒçš„æ—¶å€™": {"mood": "happy"},
            "æµªæ¼«": {"tags": ["æµªæ¼«"], "mood": "calm"},
            "å¤å¤": {"style": ["å¤å¤"]},
            "æ¸…æ–°": {"colorTone": "cold", "brightness": "bright"}
        }
        
        for keyword, intent in emotional_keywords.items():
            if keyword in query:
                return intent
        
        return {}
    
    def _build_emotional_filter(
        self,
        intent: Dict,
        context: Dict = None
    ) -> Dict:
        """
        æ„å»ºæƒ…æ„Ÿè¿‡æ»¤å™¨
        """
        filter_conditions = {}
        
        # ä»æ„å›¾ä¸­æå–è¿‡æ»¤æ¡ä»¶
        if 'mood' in intent:
            filter_conditions['emotional.mood'] = intent['mood']
        
        if 'tags' in intent:
            filter_conditions['emotional.tags'] = {"$in": intent['tags']}
        
        if 'style' in intent:
            filter_conditions['aesthetic.style'] = {"$in": intent['style']}
        
        # ä»ä¸Šä¸‹æ–‡ä¸­æå–è¿‡æ»¤æ¡ä»¶
        if context:
            if 'current_mood' in context:
                filter_conditions['emotional.mood'] = context['current_mood']
        
        # åªè¿”å›é«˜æƒé‡çš„è®°å¿†
        filter_conditions['frequency.weight'] = {"$gte": 0.5}
        
        return filter_conditions
```

---

## ğŸ§  åŠ å¼ºç‚¹ 3: å¤§å¸ˆåæ€æœºåˆ¶

### é—®é¢˜
å½“å‰çš„å¤§å¸ˆåŠŸèƒ½å¯èƒ½åœ¨è®°å¿†æ¨¡ç³Šæ—¶äº§ç”Ÿå¹»è§‰ï¼Œç¼ºå°‘è‡ªæˆ‘æ ¡å¯¹èƒ½åŠ›ã€‚

### è§£å†³æ–¹æ¡ˆ
åœ¨æ¨ç†é“¾ä¸­å¢åŠ **è‡ªæˆ‘æ ¡å¯¹æ­¥éª¤**ï¼Œè®© AI çŸ¥é“è‡ªå·±"çŸ¥ä¸çŸ¥é“"ã€‚

### å®ç°ä»£ç 

```python
# backend/master_with_reflection.py

from typing import Dict, List, Optional
from openai import OpenAI
import json

class MasterWithReflection:
    """
    å¸¦åæ€æœºåˆ¶çš„å¤§å¸ˆæ¨ç†ç³»ç»Ÿ
    """
    
    def __init__(self, user_id: str, master_type: str):
        self.user_id = user_id
        self.master_type = master_type
        self.client = OpenAI()
        self.reasoning_steps: List[Dict] = []
    
    def process_request(self, user_input: str, context: Dict) -> Dict:
        """
        å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼ˆå¸¦åæ€æœºåˆ¶ï¼‰
        """
        self.reasoning_steps = []
        
        # Step 1: ç†è§£æ„å›¾
        intent = self._understand_intent(user_input)
        self._log_step("ç†è§£æ„å›¾", intent)
        
        # Step 2: æ£€ç´¢è®°å¿†
        memories = self._retrieve_memories(user_input, intent)
        self._log_step("æ£€ç´¢è®°å¿†", f"æ‰¾åˆ° {len(memories)} æ¡è®°å¿†")
        
        # Step 2.5: è‡ªæˆ‘æ ¡å¯¹ â­ æ–°å¢
        professionalism_check = self._check_professionalism(
            user_input,
            memories,
            context
        )
        self._log_step("è‡ªæˆ‘æ ¡å¯¹", professionalism_check)
        
        # å¦‚æœçŸ¥è¯†ä¸è¶³ï¼Œè¿›è¡Œæ·±åº¦æ£€ç´¢
        if not professionalism_check['is_confident']:
            deep_memories = self._deep_search(user_input, intent)
            memories.extend(deep_memories)
            self._log_step("æ·±åº¦æ£€ç´¢", f"è¡¥å…… {len(deep_memories)} æ¡è®°å¿†")
        
        # Step 3: ç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        thinking_process = self._generate_thinking(
            user_input,
            memories,
            context
        )
        self._log_step("ç”Ÿæˆæ€è€ƒ", "æ€è€ƒè¿‡ç¨‹å·²ç”Ÿæˆ")
        
        # Step 4: ç”Ÿæˆå›ç­”
        response = self._generate_response(
            user_input,
            thinking_process,
            memories
        )
        self._log_step("ç”Ÿæˆå›ç­”", "å›ç­”å·²ç”Ÿæˆ")
        
        return {
            "response": response,
            "reasoning_chain": self.reasoning_steps,
            "confidence": professionalism_check['confidence'],
            "reflection": professionalism_check
        }
    
    def _check_professionalism(
        self,
        user_input: str,
        memories: List[Dict],
        context: Dict
    ) -> Dict:
        """
        è‡ªæˆ‘æ ¡å¯¹ - æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ä¸“ä¸šçŸ¥è¯†
        
        Returns:
            {
                "is_confident": bool,
                "confidence": float,
                "missing_knowledge": List[str],
                "reason": str
            }
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""ä½œä¸º {self.master_type} å¤§å¸ˆï¼Œè¯„ä¼°ä½ æ˜¯å¦æœ‰è¶³å¤Ÿçš„çŸ¥è¯†å›ç­”è¿™ä¸ªé—®é¢˜ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{user_input}

å¯ç”¨è®°å¿†ï¼š
{json.dumps([m.get('content', '') for m in memories[:5]], ensure_ascii=False)}

ä¸Šä¸‹æ–‡ï¼š
{json.dumps(context, ensure_ascii=False)}

è¯·è¯šå®è¯„ä¼°ï¼š
1. ä½ æ˜¯å¦æœ‰è¶³å¤Ÿçš„ä¸“ä¸šçŸ¥è¯†ï¼Ÿ
2. ç½®ä¿¡åº¦æ˜¯å¤šå°‘ï¼ˆ0-1ï¼‰ï¼Ÿ
3. ç¼ºå°‘å“ªäº›å…³é”®ä¿¡æ¯ï¼Ÿ
4. åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ

è¿”å› JSON æ ¼å¼ï¼š
{{
  "is_confident": true/false,
  "confidence": 0.0-1.0,
  "missing_knowledge": ["ç¼ºå°‘çš„çŸ¥è¯†ç‚¹1", "..."],
  "reason": "è¯„ä¼°åŸå› "
}}"""
            }],
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # å¦‚æœç½®ä¿¡åº¦ä½äº 0.7ï¼Œæ ‡è®°ä¸ºä¸è‡ªä¿¡
        if result['confidence'] < 0.7:
            result['is_confident'] = False
        
        return result
    
    def _deep_search(
        self,
        user_input: str,
        intent: Dict
    ) -> List[Dict]:
        """
        æ·±åº¦æ£€ç´¢ - å½“çŸ¥è¯†ä¸è¶³æ—¶ï¼Œæ‰©å¤§æ£€ç´¢èŒƒå›´
        """
        
        # 1. æå–ç¼ºå¤±çš„çŸ¥è¯†ç‚¹
        missing_keywords = self._extract_missing_keywords(user_input, intent)
        
        # 2. æ‰©å±•æ£€ç´¢èŒƒå›´
        deep_results = []
        for keyword in missing_keywords:
            results = self.memory_service.retrieve(
                query=keyword,
                top_k=3,
                filter={"type": {"$in": ["preference", "recipe", "footprint"]}}
            )
            deep_results.extend(results)
        
        # 3. å»é‡
        seen_ids = set()
        unique_results = []
        for result in deep_results:
            if result['id'] not in seen_ids:
                seen_ids.add(result['id'])
                unique_results.append(result)
        
        return unique_results
    
    def _extract_missing_keywords(
        self,
        user_input: str,
        intent: Dict
    ) -> List[str]:
        """
        æå–ç¼ºå¤±çš„å…³é”®è¯
        """
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"""ä»è¿™ä¸ªé—®é¢˜ä¸­æå–å…³é”®è¯ï¼Œç”¨äºæ‰©å±•æ£€ç´¢ï¼š

é—®é¢˜ï¼š{user_input}
æ„å›¾ï¼š{json.dumps(intent, ensure_ascii=False)}

è¿”å› JSON æ•°ç»„æ ¼å¼ï¼š
["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"]"""
            }],
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        return result.get('keywords', [])
    
    def _log_step(self, description: str, result: any):
        """è®°å½•æ¨ç†æ­¥éª¤"""
        self.reasoning_steps.append({
            "step": len(self.reasoning_steps) + 1,
            "description": description,
            "result": result
        })


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    master = MasterWithReflection(
        user_id="test_user",
        master_type="æ‘„å½±å¤§å¸ˆ"
    )
    
    result = master.process_request(
        user_input="å¦‚ä½•åœ¨é›¨å¤©æ‹å‡ºç”µå½±æ„Ÿï¼Ÿ",
        context={
            "device": "iPhone 15 Pro",
            "location": "ä¸Šæµ·",
            "weather": "é›¨å¤©"
        }
    )
    
    print("=== å¤§å¸ˆå›ç­” ===")
    print(result['response'])
    print(f"\nç½®ä¿¡åº¦ï¼š{result['confidence']}")
    print(f"\nåæ€ç»“æœï¼š")
    print(json.dumps(result['reflection'], ensure_ascii=False, indent=2))
    print(f"\næ¨ç†é“¾ï¼š")
    for step in result['reasoning_chain']:
        print(f"  {step['step']}. {step['description']}")
```

---

## ğŸ¯ åŠ å¼ºç‚¹ 4: é¢„æµ‹æ€§äº¤äº’ UI

### é—®é¢˜
å½“å‰ UI æ˜¯è¢«åŠ¨çš„ï¼Œç”¨æˆ·éœ€è¦ä¸»åŠ¨ç‚¹å‡»æ‰èƒ½ä½¿ç”¨åŠŸèƒ½ã€‚

### è§£å†³æ–¹æ¡ˆ
å®ç°**å‰ç½®è§¦å‘ï¼ˆPre-fetchingï¼‰UI**ï¼Œä¸»åŠ¨æ¨é€æ™ºèƒ½å»ºè®®ã€‚

### å®ç°ä»£ç 

```typescript
// src/components/PredictiveUI.tsx

import React, { useEffect, useState } from 'react';
import { View, Text, TouchableOpacity, Animated, StyleSheet } from 'react-native';
import * as Location from 'expo-location';
import MasterService from '../services/MasterService';
import MemoryService from '../services/MemoryService';

interface Suggestion {
  id: string;
  type: 'camera' | 'edit' | 'location';
  title: string;
  description: string;
  action: () => void;
  confidence: number;
}

const PredictiveUI: React.FC = () => {
  const [suggestion, setSuggestion] = useState<Suggestion | null>(null);
  const [fadeAnim] = useState(new Animated.Value(0));
  
  useEffect(() => {
    // å¯åŠ¨é¢„æµ‹å¼•æ“
    startPredictiveEngine();
  }, []);
  
  /**
   * å¯åŠ¨é¢„æµ‹å¼•æ“
   */
  const startPredictiveEngine = async () => {
    // 1. è·å–å½“å‰ä¸Šä¸‹æ–‡
    const context = await getCurrentContext();
    
    // 2. é¢„æµ‹ç”¨æˆ·æ„å›¾
    const intent = await predictUserIntent(context);
    
    // 3. ç”Ÿæˆå»ºè®®
    if (intent && intent.confidence > 0.7) {
      const suggestion = await generateSuggestion(intent, context);
      
      if (suggestion) {
        setSuggestion(suggestion);
        showSuggestion();
      }
    }
  };
  
  /**
   * è·å–å½“å‰ä¸Šä¸‹æ–‡
   */
  const getCurrentContext = async () => {
    const location = await Location.getCurrentPositionAsync({});
    const time = new Date();
    const hour = time.getHours();
    
    return {
      location: {
        latitude: location.coords.latitude,
        longitude: location.coords.longitude
      },
      time: {
        hour,
        period: hour < 12 ? 'morning' : hour < 18 ? 'afternoon' : 'evening'
      },
      weather: await getWeather(location.coords),
      device: 'iPhone 15 Pro'
    };
  };
  
  /**
   * é¢„æµ‹ç”¨æˆ·æ„å›¾
   */
  const predictUserIntent = async (context: any) => {
    const memoryService = MemoryService.getInstance('user_123');
    
    // 1. æ£€ç´¢ç›¸ä¼¼åœºæ™¯çš„å†å²è¡Œä¸º
    const memories = await memoryService.retrieve(
      `${context.location.latitude},${context.location.longitude} ${context.time.period}`,
      {
        type: 'footprint',
        topK: 5
      }
    );
    
    // 2. åˆ†æè¡Œä¸ºæ¨¡å¼
    const behaviorPattern = analyzeBehaviorPattern(memories);
    
    // 3. è®¡ç®—æ„å›¾ç½®ä¿¡åº¦
    if (behaviorPattern.frequency > 3) {
      return {
        type: behaviorPattern.mostCommonAction,
        confidence: Math.min(behaviorPattern.frequency / 5, 1.0),
        reason: `ç”¨æˆ·åœ¨æ­¤åœ°ç‚¹å’Œæ—¶é—´æ®µç»å¸¸${behaviorPattern.mostCommonAction}`
      };
    }
    
    // 4. åŸºäºåœ°ç‚¹ç‰¹å¾é¢„æµ‹
    if (isNearWater(context.location)) {
      return {
        type: 'camera',
        confidence: 0.75,
        reason: 'æ£€æµ‹åˆ°æ‚¨æ­£åœ¨æµ·è¾¹ï¼Œé€‚åˆæ‹ç…§'
      };
    }
    
    return null;
  };
  
  /**
   * åˆ†æè¡Œä¸ºæ¨¡å¼
   */
  const analyzeBehaviorPattern = (memories: any[]) => {
    const actions: Record<string, number> = {};
    
    memories.forEach(memory => {
      const action = memory.metadata.action || 'unknown';
      actions[action] = (actions[action] || 0) + 1;
    });
    
    const mostCommonAction = Object.keys(actions).reduce((a, b) => 
      actions[a] > actions[b] ? a : b
    );
    
    return {
      mostCommonAction,
      frequency: actions[mostCommonAction] || 0
    };
  };
  
  /**
   * ç”Ÿæˆå»ºè®®
   */
  const generateSuggestion = async (intent: any, context: any): Promise<Suggestion | null> => {
    const masterService = MasterService.getInstance('user_123');
    
    switch (intent.type) {
      case 'camera':
        const cameraAdvice = await masterService.getAdvice(
          'photography',
          'å½“å‰åœºæ™¯é€‚åˆæ‹ç…§å—ï¼Ÿ',
          context
        );
        
        return {
          id: 'camera_suggestion',
          type: 'camera',
          title: 'ğŸ“· å¼€å¯å¤§å¸ˆæ‹æ‘„æ¨¡å¼ï¼Ÿ',
          description: cameraAdvice.advice.substring(0, 50) + '...',
          action: () => {
            // å¯¼èˆªåˆ°ç›¸æœºé¡µé¢
            navigation.navigate('Camera', { 
              masterMode: true,
              preset: cameraAdvice.metadata?.preset
            });
          },
          confidence: intent.confidence
        };
      
      case 'edit':
        return {
          id: 'edit_suggestion',
          type: 'edit',
          title: 'âœ¨ ç»§ç»­ç¼–è¾‘æ˜¨å¤©çš„ç…§ç‰‡ï¼Ÿ',
          description: 'æ ¹æ®æ‚¨çš„ä¹ æƒ¯ï¼Œæ¨èä½¿ç”¨"å¤å¤"æ»¤é•œ',
          action: () => {
            navigation.navigate('Editor', { 
              preset: 'vintage'
            });
          },
          confidence: intent.confidence
        };
      
      case 'location':
        return {
          id: 'location_suggestion',
          type: 'location',
          title: 'ğŸ“ é™„è¿‘æœ‰æ¨èçš„æ‹æ‘„åœ°ç‚¹',
          description: 'å¤–æ»©å¤œæ™¯æ­£å½“æ—¶ï¼Œè·ç¦»æ‚¨ 2.3km',
          action: () => {
            navigation.navigate('Map', { 
              highlight: 'bund'
            });
          },
          confidence: intent.confidence
        };
      
      default:
        return null;
    }
  };
  
  /**
   * æ˜¾ç¤ºå»ºè®®
   */
  const showSuggestion = () => {
    Animated.timing(fadeAnim, {
      toValue: 1,
      duration: 300,
      useNativeDriver: true
    }).start();
  };
  
  /**
   * éšè—å»ºè®®
   */
  const hideSuggestion = () => {
    Animated.timing(fadeAnim, {
      toValue: 0,
      duration: 200,
      useNativeDriver: true
    }).start(() => {
      setSuggestion(null);
    });
  };
  
  if (!suggestion) {
    return null;
  }
  
  return (
    <Animated.View 
      style={[
        styles.container,
        { opacity: fadeAnim }
      ]}
    >
      <View style={styles.card}>
        <View style={styles.header}>
          <Text style={styles.title}>{suggestion.title}</Text>
          <TouchableOpacity onPress={hideSuggestion}>
            <Text style={styles.closeButton}>âœ•</Text>
          </TouchableOpacity>
        </View>
        
        <Text style={styles.description}>{suggestion.description}</Text>
        
        <View style={styles.actions}>
          <TouchableOpacity 
            style={styles.dismissButton}
            onPress={hideSuggestion}
          >
            <Text style={styles.dismissText}>ç¨å</Text>
          </TouchableOpacity>
          
          <TouchableOpacity 
            style={styles.actionButton}
            onPress={() => {
              suggestion.action();
              hideSuggestion();
            }}
          >
            <Text style={styles.actionText}>ç«‹å³ä½“éªŒ</Text>
          </TouchableOpacity>
        </View>
        
        <View style={styles.confidence}>
          <Text style={styles.confidenceText}>
            æ™ºèƒ½æ¨è Â· ç½®ä¿¡åº¦ {(suggestion.confidence * 100).toFixed(0)}%
          </Text>
        </View>
      </View>
    </Animated.View>
  );
};

const styles = StyleSheet.create({
  container: {
    position: 'absolute',
    bottom: 100,
    left: 20,
    right: 20,
    zIndex: 1000
  },
  card: {
    backgroundColor: 'rgba(20, 20, 30, 0.95)',
    borderRadius: 16,
    padding: 20,
    borderWidth: 1,
    borderColor: '#A33BFF',
    shadowColor: '#A33BFF',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 8
  },
  header: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    marginBottom: 12
  },
  title: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#FFFFFF'
  },
  closeButton: {
    fontSize: 24,
    color: '#999',
    padding: 4
  },
  description: {
    fontSize: 14,
    color: '#CCCCCC',
    marginBottom: 16,
    lineHeight: 20
  },
  actions: {
    flexDirection: 'row',
    gap: 12
  },
  dismissButton: {
    flex: 1,
    padding: 12,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: '#666',
    alignItems: 'center'
  },
  dismissText: {
    color: '#CCCCCC',
    fontSize: 16,
    fontWeight: '600'
  },
  actionButton: {
    flex: 1,
    padding: 12,
    borderRadius: 8,
    backgroundColor: '#A33BFF',
    alignItems: 'center'
  },
  actionText: {
    color: '#FFFFFF',
    fontSize: 16,
    fontWeight: '600'
  },
  confidence: {
    marginTop: 12,
    paddingTop: 12,
    borderTopWidth: 1,
    borderTopColor: '#333'
  },
  confidenceText: {
    fontSize: 12,
    color: '#999',
    textAlign: 'center'
  }
});

export default PredictiveUI;
```

---

## ğŸ“Š å®Œæ•´çš„éªŒæ”¶æ ‡å‡†

### Day 1: æ¶æ„æ ¡å¯¹
- [ ] åŒè½¨åˆ¶æ¥å£éƒ¨ç½²å®Œæˆ
- [ ] é™çº§ä¿æŠ¤æµ‹è¯•é€šè¿‡ï¼ˆAI è¶…æ—¶èƒ½è‡ªåŠ¨åˆ‡æ¢ï¼‰
- [ ] å¥åº·æ£€æŸ¥ç³»ç»Ÿè¿è¡Œæ­£å¸¸

### Day 2: å¤§å¸ˆé‡å¡‘
- [ ] åæ€æœºåˆ¶å®ç°
- [ ] è‡ªæˆ‘æ ¡å¯¹åŠŸèƒ½æµ‹è¯•é€šè¿‡
- [ ] ç½®ä¿¡åº¦ä½äº 0.7 æ—¶èƒ½è‡ªåŠ¨æ·±åº¦æ£€ç´¢

### Day 3: è®°å¿†æ¥å…¥
- [ ] æƒ…æ„Ÿæ ‡ç­¾ç³»ç»Ÿéƒ¨ç½²
- [ ] æ“ä½œé¢‘ç‡æƒé‡è®¡ç®—æ­£ç¡®
- [ ] æƒ…æ„Ÿåˆ†æ API å¯ç”¨

### Day 4: åª’ä½“é›†æˆ
- [ ] è¯­ä¹‰ä¿®å›¾åŠŸèƒ½å®ç°
- [ ] "æ˜¨å¤©çš„æ„Ÿè§‰"èƒ½ç²¾å‡†è¿˜åŸå‚æ•°
- [ ] é…æ–¹è®°å¿†æŒ‰æƒé‡æ’åº

### Day 5: åœ°å›¾é›†æˆ
- [ ] åŠ¨æ€é¿é›·åŠŸèƒ½å®ç°
- [ ] ä¸»åŠ¨æ¨èå‘½ä¸­ç‡ > 60%
- [ ] è´Ÿé¢åœ°ç‚¹è‡ªåŠ¨è¿‡æ»¤

### Day 6: UI/UX ä¼˜åŒ–
- [ ] é¢„æµ‹æ€§äº¤äº’ UI éƒ¨ç½²
- [ ] å‰ç½®è§¦å‘åŠŸèƒ½æµ‹è¯•é€šè¿‡
- [ ] ç®€ä½“ä¸­æ–‡è§„èŒƒå®¡è®¡é€šè¿‡

### Day 7: æµ‹è¯•ä¸Šçº¿
- [ ] å‹åŠ›æµ‹è¯•é€šè¿‡ï¼ˆ1000 å¹¶å‘ï¼‰
- [ ] è®°å¿†æ£€ç´¢ + æ¨ç†å»¶è¿Ÿ < 200ms
- [ ] ç³»ç»Ÿå¯ç”¨æ€§ > 99.9%

---

**æ–‡æ¡£ä½œè€…**: Jason Tsao  
**æ›´æ–°æ—¶é—´**: 2026å¹´1æœˆ17æ—¥  
**ç‰ˆæœ¬**: Enhanced 2.0

**æŒ‰ç…§è¿™ä¸ªåŠ å¼ºç‰ˆæ–¹æ¡ˆæ‰§è¡Œï¼Œè®© yanbao AI çœŸæ­£å…·å¤‡"çµé­‚"ï¼** ğŸš€
